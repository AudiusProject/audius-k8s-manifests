---
# Source: audius-logger/templates/fluentd-cm.yaml

apiVersion: v1
kind: ConfigMap
metadata:
  name: fluentd-cm
  namespace: kube-system
data:
  source.conf: |
    

    <source>
      tag audius.js.*
      @type tail
      @id in_tail_audius_js_container_logs
      path /var/log/containers/creator*.log, /var/log/containers/content*.log, /var/log/containers/identity*.log
      pos_file /var/log/audius-fluentd-js-containers.log.pos
      read_from_head true
      <parse>
        @type json
        time_key time
        time_format %Y-%m-%dT%H:%M:%S.%NZ
      </parse>
    </source>

    <filter audius.js.**>
      @type parser
      key_name log
      <parse>
        @type json
        time_key time
        time_format %Y-%m-%dT%H:%M:%S.%NZ
      </parse>
    </filter>

    <filter audius.js.**>
      @type record_transformer
      enable_ruby
      <record>
        log_level ${ if record["level"] == 60 then "fatal" elsif record["level"] == 50 then "error" elsif record["level"] == 40 then "warn" elsif record["level"] == 30 then "info" elsif record["level"] == 20 then "debug" elsif record["level"] == 10 then "trace" end}
      </record>
      remove_keys level,pid,v
    </filter>

    <filter audius.js.**>
      @type grep
      <regexp>
        key log_level
        pattern /^(?:info|warn|error|fatal)$/
      </regexp>
    </filter>
    
    <source>
      tag audius.py.server.*
      @type tail
      @id in_tail_audius_py_server_container_logs
      path /var/log/containers/discovery*server*.log
      pos_file /var/log/audius-fluentd-py-server-containers.log.pos
      read_from_head true
      <parse>
        @type json
        time_key time
        time_format %Y-%m-%dT%H:%M:%S.%NZ
      </parse>
    </source>

    <source>
      tag audius.py.worker.*
      @type tail
      @id in_tail_audius_py_worker_container_logs
      path /var/log/containers/discovery*worker*.log, /var/log/containers/discovery*beat*.log
      pos_file /var/log/audius-fluentd-py-worker-containers.log.pos
      read_from_head true
      <parse>
        @type json
        time_key time
        time_format %Y-%m-%dT%H:%M:%S.%NZ
      </parse>
    </source>

    <filter audius.py.**>
      @type parser
      key_name log
      <parse>
        @type json
        time_key time
        time_format %Y-%m-%dT%H:%M:%S.%NZ
      </parse>
    </filter>

    <filter audius.py.**>
      @type record_transformer
      enable_ruby
      <record>
        log_level ${ if record["level"] == "CRITICAL" then "fatal" elsif record["level"] == "ERROR" then "error" elsif record["level"] == "WARNING" then "warn" elsif record["level"] == "INFO" then "info" elsif record["level"] == "DEBUG" then "debug" elsif record["level"] == "NOTSET" then "trace" end}
      </record>
      remove_keys level
    </filter>

    <filter audius.py.**>
      @type grep
      <regexp>
        key log_level
        pattern /^(?:info|warn|error|fatal)$/
      </regexp>
    </filter>

    
    <filter audius.**>
      @type kubernetes_metadata
      @id filter_audius_kube_metadata
    </filter>
    

  fluent-loggly.conf: |
    @include source.conf

    <match audius.**>
      @type loggly
      @id out_loggly
      loggly_url "https://logs-01.loggly.com/bulk/#{ENV['LOGGLY_TOKEN']}/tag/#{ENV['LOGGLY_TAGS'] || 'fluentd'}/bulk"
    </match>


---
# Source: audius-logger/templates/fluentd-rbac.yaml

apiVersion: v1
kind: ServiceAccount
metadata:
  name: fluentd
  namespace: kube-system

---
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRole
metadata:
  name: fluentd
  namespace: kube-system
rules:
- apiGroups:
  - ""
  resources:
  - pods
  - namespaces
  verbs:
  - get
  - list
  - watch

---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: fluentd
roleRef:
  kind: ClusterRole
  name: fluentd
  apiGroup: rbac.authorization.k8s.io
subjects:
- kind: ServiceAccount
  name: fluentd
  namespace: kube-system


---
# Source: audius-logger/templates/fluentd-ds.yaml



apiVersion: apps/v1


kind: DaemonSet
metadata:
  name: fluentd
  namespace: kube-system
  labels:
    app: fluentd
    tier: logs
spec:
  
  # extra selector needed in apps/v1 to support service providers
  selector:
    matchLabels:
      app: fluentd
  
    
  template:
    metadata:
      labels:
        app: fluentd
        tier: logs
    spec:
      serviceAccount: fluentd
      serviceAccountName: fluentd
      tolerations:
      - key: node-role.kubernetes.io/master
        effect: NoSchedule
      containers:
      
      - name: fluentd-loggly
        image: fluent/fluentd-kubernetes-daemonset:v1-debian-loggly
        env:
        - name: LOGGLY_TAGS
          value: external,<SP_NAME>,<SP_NAME_TYPE_ID>
        envFrom:
        - secretRef:
            name: fluentd-secrets-service-providers
        resources:
          limits:
            memory: 200Mi
          requests:
            cpu: 100m
            memory: 200Mi
        volumeMounts:
        - name: varlog
          mountPath: /var/log
        - name: varlibdockercontainers
          mountPath: /var/lib/docker/containers
          readOnly: true
        - name: fluentd-cm
          mountPath: /fluentd/etc/source.conf
          subPath: source.conf
        - name: fluentd-cm
          mountPath: /fluentd/etc/fluent.conf
          subPath: fluent-loggly.conf
      
      
      terminationGracePeriodSeconds: 30
      volumes:
      - name: varlog
        hostPath:
          path: /var/log
      - name: varlibdockercontainers
        hostPath:
          path: /var/lib/docker/containers
      - name: fluentd-cm
        configMap:
          name: fluentd-cm


